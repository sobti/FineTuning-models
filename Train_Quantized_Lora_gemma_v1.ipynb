{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nietph-JEanZ"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets peft bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgJLXicU_Mgp"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 38657,
     "status": "ok",
     "timestamp": 1755419414873,
     "user": {
      "displayName": "Punit Sobti",
      "userId": "07835938569637239840"
     },
     "user_tz": -330
    },
    "id": "BFrlQGjyEktd"
   },
   "outputs": [],
   "source": [
    "import torch as torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,Gemma3ForCausalLM,BitsAndBytesConfig\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1755419414874,
     "user": {
      "displayName": "Punit Sobti",
      "userId": "07835938569637239840"
     },
     "user_tz": -330
    },
    "id": "SLxVMkBBFN_C"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "#from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301,
     "referenced_widgets": [
      "de189ec3110e47999174de24a2d3a71e",
      "5e04259be83d44639e18bf70e9621266",
      "d5e799eaaf884f4ab7674488f745d7cb",
      "a62772513097455d8ecb31de852f6c50",
      "01a3bda780f540f5aab080cce4178b0f",
      "eb0f0723770a41fda2967921afc77237",
      "ab1bbabcbb8540aeaddd207e750a090c",
      "ab72ff6ae2914568ada87795e1508e7f",
      "27a19403a94541a8a68e03b9a89500f2",
      "043aab329f6c40b3b35e1799a6a92231",
      "8e1f40a4a319452e8717472cb1ed05c8",
      "ade65a12805c4b038be381217f3e2fcb",
      "6f07352b59c7455b8cf95262a0d7c257",
      "72939f319d7c40e58b657476acc4a0a6",
      "0935f47e86c04df59bcd3b37c12f0d8b",
      "55e38a0da4084e36a6c799aac1894598",
      "1918c49c5e8d45298fbad4e5754aa158",
      "81df2452849741f6adfe37d7a011d426",
      "2d6b3bea07414d3ba024e771c2484073",
      "f0486571cb8148d3bd3f0ae990aa3408",
      "1728faf3570742708c631a881df79be5",
      "8c5b582dbe664942a86be88c086eb210",
      "1a81381706704a459270163e65ed8715",
      "7c8600b3dec84446aa6859bb5d7bd910",
      "a15e864b9de4429190f1936f826f946e",
      "b8455fa86e68483cb23295df458e80bb",
      "1002936f38c442d79edbe37d7f675711",
      "d158c0d5f69944a8845dc00936e75237",
      "598298e6fccf4331b7fe9b58cde6f27b",
      "fc19163628e9498c80a113b1fc462106",
      "0dfa8e7e4f0641ed945186008255ddba",
      "733a8e2e72fb4db392922cd9e8211b0d",
      "dc845bdfeae241bba7ad9b999e1a15cb",
      "8c77ea9656314fd3b4f22471ffde5147",
      "5d242470ebaf4955986b3528d8ba5fb7",
      "950403942d654dddb8b151d220b4e048",
      "9e858a9cf9d34c18acdbaaaaa221a056",
      "2d75bbe3a4c54daa9e16c2c7b3fb80d4",
      "cd2d1f84fd85459199f7c7dbf33bb021",
      "64f7bfba6aa4489aa095e708e72dcc6c",
      "acafd89dcd7e46a39129716bb15a81d8",
      "94f2728165ed430f9dc485b77b365c1c",
      "1af7e0680c354894ac31d2ebcea74b4a",
      "c50234cc8f4e4738b8580eea4f9378a2",
      "641212b40ef54a9795297554571c2bdf",
      "4f8febce396f4c679007dbfa36ab386d",
      "fdbdd7ff237b4e86ab97237a58a18a3c",
      "cebd1044ef024fbd9061a9c48d183fff",
      "b489aa7cf3b9487f81d1c8757722514f",
      "f25f6b7082c94e788bf401e25e2350fa",
      "630a15abbb26418da3404e742655cc2d",
      "f35c8fb6cf2d47869445f3a758363e8f",
      "0a1f88445c2946d4a0a746f1dbf20468",
      "a4e3158c0e23462e9a1fc63b56d5ae2c",
      "0a754007e0424c9cb4536d2a68c7c671"
     ]
    },
    "executionInfo": {
     "elapsed": 4662,
     "status": "ok",
     "timestamp": 1755419419532,
     "user": {
      "displayName": "Punit Sobti",
      "userId": "07835938569637239840"
     },
     "user_tz": -330
    },
    "id": "2Ol2o4hHGsz-",
    "outputId": "c156442d-d2c6-4a46-91af-e776997520f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de189ec3110e47999174de24a2d3a71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade65a12805c4b038be381217f3e2fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-b42a775f407cee45.parquet:   0%|          | 0.00/39.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a81381706704a459270163e65ed8715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-134b8fd0c89408b6.parquet:   0%|          | 0.00/2.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c77ea9656314fd3b4f22471ffde5147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/84437 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641212b40ef54a9795297554571c2bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/4401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data=load_dataset(\"OpenAssistant/oasst1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvDySwCuZ3Lw"
   },
   "outputs": [],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 48438,
     "status": "ok",
     "timestamp": 1755419467975,
     "user": {
      "displayName": "Punit Sobti",
      "userId": "07835938569637239840"
     },
     "user_tz": -330
    },
    "id": "tRFABKurHOck"
   },
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "# Group by message_id manually\n",
    "conversations = defaultdict(list)\n",
    "conversations_v = defaultdict(list)\n",
    "for row in data['train']:\n",
    "    conversations[row[\"message_tree_id\"]].append((row[\"role\"], row[\"text\"]))\n",
    "\n",
    "# Convert to list of dicts for Dataset\n",
    "formatted = []\n",
    "for convo_id, turns in conversations.items():\n",
    "    convo_parts = []\n",
    "    for role, content in turns:\n",
    "        if role == \"prompter\":\n",
    "            convo_parts.append(f\"<start_of_turn>\\n{content.strip()}<end_of_turn>\")\n",
    "        elif role == \"assistant\":\n",
    "            convo_parts.append(f\"<start_of_turn>\\n{content.strip()}<end_of_turn>\")\n",
    "    chat_str = \"<bos>\" + \"\\n\".join(convo_parts) + \"<eos>\"\n",
    "    formatted.append({\"input_ids\":chat_str})\n",
    "\n",
    "for row in data['validation']:\n",
    "    conversations_v[row[\"message_tree_id\"]].append((row[\"role\"], row[\"text\"]))\n",
    "\n",
    "# Convert to list of dicts for Dataset\n",
    "formatted_v = []\n",
    "for convo_id, turns in conversations_v.items():\n",
    "    convo_parts = []\n",
    "    for role, content in turns:\n",
    "        if role == \"prompter\":\n",
    "            convo_parts.append(f\"<start_of_turn>\\n{content.strip()}<end_of_turn>\")\n",
    "        elif role == \"assistant\":\n",
    "            convo_parts.append(f\"<start_of_turn>\\n{content.strip()}<end_of_turn>\")\n",
    "    chat_str = \"<bos>\" + \"\\n\".join(convo_parts) + \"<eos>\"\n",
    "    formatted_v.append({\"input_ids\":chat_str})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 790,
     "status": "ok",
     "timestamp": 1755419468759,
     "user": {
      "displayName": "Punit Sobti",
      "userId": "07835938569637239840"
     },
     "user_tz": -330
    },
    "id": "5yC8EADZc2ww"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "train=Dataset.from_list(formatted)\n",
    "validate=Dataset.from_list(formatted_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1755419230591,
     "user": {
      "displayName": "Punit Sobti",
      "userId": "07835938569637239840"
     },
     "user_tz": -330
    },
    "id": "LOBtqWkiHm59"
   },
   "outputs": [],
   "source": [
    "DataLoaders=DataLoader(data,batch_size=8) # Not required with hugging face Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1755419468843,
     "user": {
      "displayName": "Punit Sobti",
      "userId": "07835938569637239840"
     },
     "user_tz": -330
    },
    "id": "PuoaeZbwNQPk"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1755418043156,
     "user": {
      "displayName": "Punit Sobti",
      "userId": "07835938569637239840"
     },
     "user_tz": -330
    },
    "id": "ft2GAxvXO_eF"
   },
   "outputs": [],
   "source": [
    "# Not required as of now\n",
    "from torch.utils.data import Dataset\n",
    "class dataset(Dataset):\n",
    "    def __init__(self,data):\n",
    "        super().__init__()\n",
    "        self.data=data\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\")\n",
    "    def __len__(self):\n",
    "        return len(self.data['train'])\n",
    "    def __getitem__(self,idx):\n",
    "        prompt = f\"### Instruction:\\n{self.data['train'][idx]['instruction']}\\n### Input:\\n{self.data['train'][idx]['input']}\\n### Response:\\n{self.data['train'][idx]['output']}\"\n",
    "        tokenized_prompt = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "        return tokenized_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 557,
     "status": "ok",
     "timestamp": 1755419469402,
     "user": {
      "displayName": "Punit Sobti",
      "userId": "07835938569637239840"
     },
     "user_tz": -330
    },
    "id": "eqQrCWOfB-WQ"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "c05a519716674ee69479b1780a9fa87a",
      "e3713b9b29b14abcb47cdb0d03869d84",
      "e6cd2015d77b4ba693a17bb28d79b04c",
      "b29aba804779463a944ccd0c76a88bde",
      "91edb75d9dc944faa153963739e68cfa",
      "dcaa3b5fcc5a4d81bbdd7347df00bcb3",
      "e53a4f8c648a486ea25c18364a28ae55",
      "903be9fbf9d441639288a0042b531f04",
      "6c89c6a6fd2c4018bbd37261b270729b",
      "fc90cd9328d5497fa114e4ac966da8ea",
      "dd0164a1ff004cbe80f2b9ee22cc1cc2",
      "b372a622c26449bc89e4c5c30fb2e03f",
      "23c55071342e4faa83a6b76608ff4d4e",
      "fad9f30c4fa94920a072a7833e999d12",
      "3a4762d9009c402ba9d2badcd618cb26",
      "54857b18fa644ed98013726a0ceb9cad",
      "9dbcc9cd23e14e0f873c591f8cf97fdf",
      "c3832e4befb74c8e8a30a967243a512c",
      "5630d71cac7e40058a8b043ce80dd149",
      "0b04d6aa4a3e4ac1af7f7f7d9199864b",
      "e042554979f74443967e2c12227ae5eb",
      "be03ba0bd6b54f638da672e95238be38",
      "9f7aafec54fd4ac6a59c08609b783c81",
      "e44129b0dd7c4c5bbd768b9a3979b91c",
      "22e1c90500714f84921039a4dd1de8a1",
      "a5d319e511e54ade9d7e032a46e51b02",
      "4add6ae47f5147a2bd0c58c4d24224d1",
      "596d80df6d19442b814f0b8c1866b43a",
      "63440e63e48d4b26b0f77bbdf923130c",
      "ed1536564bda4633886dea945c21bd76",
      "273dd685128f4b1e8f47aa35dc9581f2",
      "50da2617c2be4a0fbacdbe7c87083c95",
      "1353d07754dc47569bde9647c1e5e1de",
      "46a50c93f1c547afb3e4c2c3fb3237c0",
      "b8910f9bc6504c558fa2ae3db4a2dfa1",
      "4f5d1c416ddb46ccb6c0c8036ce071a6",
      "cf24879a0952407daf94e1fca43a7586",
      "ae34380daee044fc848b638f36242c64",
      "c39eb29483af4fd7a38883119894ff07",
      "cf284f6614664dff80bd7577e4029df4",
      "3c83fbcd1f0e4bb486206caa97873b27",
      "3aaf6b4dfe7e43d6a2b9ee672027c426",
      "ac118631c04141a597852b2e4705cfa4",
      "f07c36f751e54d28bb09a027a6ad8142"
     ]
    },
    "executionInfo": {
     "elapsed": 3729,
     "status": "ok",
     "timestamp": 1755419473134,
     "user": {
      "displayName": "Punit Sobti",
      "userId": "07835938569637239840"
     },
     "user_tz": -330
    },
    "id": "sl4_NdPjU044",
    "outputId": "0de62b2d-8d79-4b88-ea34-355a34a99a50"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05a519716674ee69479b1780a9fa87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/34.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b372a622c26449bc89e4c5c30fb2e03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7aafec54fd4ac6a59c08609b783c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a50c93f1c547afb3e4c2c3fb3237c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_id = \"google/gemma-2b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_bos_token=False\n",
    "tokenizer.add_eos_token=False\n",
    "#special_tokens = [\"|assistant|\", \"|prompter|\"]\n",
    "#tokenizer.add_special_tokens({\"additional_special_tokens\": special_tokens})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "68ac173139b145bf97358bb52b1d8cd8",
      "0dd66fb8b11d43f0a34f57041cb18ae0",
      "4de775236ee440f8b93ac264d863f288",
      "2a34d2f2f3034c8aa03a969c13d22934",
      "bb43c215b716445c96ca924efa4d3483",
      "88c57aec8bb14665b05a0cc524260571",
      "bb9ffa4c38484fd3a2ba2b9a161213fd",
      "71f8f93cf2b447b69d3dfd0788869070",
      "0c52621006264ae0a3359eae64c7fb1e",
      "49dd07904ee94fe183207234339c9863",
      "bf13ab774e2f4dacb194cc732d4a9798",
      "8e5ca86ba6494ec085abcbd645f1a8ef",
      "3d984fb307344228b502f89a85d4b928",
      "a6e80565405e4054b60afd2f5af55813",
      "78111153088a4f3785884f431328df45",
      "18283f955a48475d9ac283b3f3bafb55",
      "e08f2e82c99c42ed9d8c9e79b924536f",
      "f2e5324de1d64bfdbad3758e329cceeb",
      "193d8a04366a45babf7545148edddeec",
      "94a677890117444ea4205726dd5eb802",
      "d5548d2b31b84f439d54a5de2bbb50e5",
      "82ada1b7f3124d3ab3a72527af340fef"
     ]
    },
    "executionInfo": {
     "elapsed": 20498,
     "status": "ok",
     "timestamp": 1755419493635,
     "user": {
      "displayName": "Punit Sobti",
      "userId": "07835938569637239840"
     },
     "user_tz": -330
    },
    "id": "KYToZ7UicBAY",
    "outputId": "2de2c341-512f-43c7-d6ca-6749bf05aefe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ac173139b145bf97358bb52b1d8cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9846 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5ca86ba6494ec085abcbd645f1a8ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/518 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"input_ids\"],\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=False  # Let data_collator handle padding\n",
    "    )\n",
    "\n",
    "train = train.map(tokenize_fn, batched=True)\n",
    "validate = validate.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "0dbb1af5f0f9413c980f43c4c1107126",
      "9e76860b979548c3b99f0230a2b92fcc",
      "ad4a7028454c46ed82bf66f9d015d142",
      "9f85b271d0db4d81a8bc6d353e7fb928",
      "8cba7bbbbd9b4ed594f4b9e570c6b4db",
      "37a6b5ea81ab4eaeabb1571a54dcdb22",
      "735b567134854fe08985d1c108f22833",
      "9fb5b1d62727477c860598935b4f6248",
      "1867e5ff6c4948b489caf5a904109f41",
      "11d113727e1742878a09ab95d5df1bc0",
      "2fdf237f541b4375981e4bbeb7f895a0",
      "53520b9d6e7f4d748700fbbb526d4b68",
      "55a47cc2f7a0440dafa5d3ac87a4b910",
      "50ebb036ecd9462baa61d7d6c115f251",
      "32c90e73d86247438c9d9b0380a776bd",
      "5ef885385c0e403e8ad5d29b2e6c7152",
      "cf6facbf02a14828bdb81b1bd5273186",
      "759c1c927ffd47ea92b86913b2ea69e9",
      "91fd35fb634c420d8e450d259df21816",
      "cfab3fdded2d45fe98e80c1060475df1",
      "8f8e31c9a7424c1eb0d1d934145e2b60",
      "3134d8ea491548809238c884d4fd6da3",
      "203cfc5a56cb4d22b663eb38a7896a0d",
      "1b74e4d91810435d98d88b20f7d3111a",
      "0561ade664b84ce9aaaa53bbda04aa42",
      "9310370731a64fa38d65acf86823d3fc",
      "61d76957ce8444c5b1c17466146605c9",
      "d9af1dfe2d0e45349e85fe2fe7dd1b07",
      "fcac98e7985e4e3688f0a3c34e80d21a",
      "10a791ae052040f2bf3c32ee30a41ee9",
      "6ae70f1e7e784ee393e969e7727ddea5",
      "df471cd6a2454343bab530da8b32643e",
      "a89663d324074367b78271cbc4c6c4aa",
      "6087ed7953a54aba9e7d0fbe8dd33371",
      "d996e1a7b23848129040a342eb976b3b",
      "3587831f4e26433a9784b76cfd1f3c0b",
      "ea3311592124485787e2346975c29247",
      "cea0aec93cc6417cbd52eba45fc42f16",
      "e1c126ceabb340e4ae3c380b11864b82",
      "17c345b5f86e4463a51656de2f031ce5",
      "c7a9736a445b4db78693a7f8b1128e30",
      "081233f177f642979bec5db1ca701ae0",
      "0356ead5009c4ad98572a414dad1d07c",
      "e86e4a27b40c47e1ba3b78e4e3991e8f",
      "c28820bb97b944f2a2d00645ff9ff5e5",
      "ab8973260efc4ca0b8de805454d7fa76",
      "eb97862b0af647beae24f5e658e3b34f",
      "5d0d23a648644e71964b933c500e4bf1",
      "3b9bc6902d314847ada1c36182b0a34e",
      "1299c078da3e4626937526905b069c41",
      "149d3c89fb084bf48b125e2897322644",
      "c2ffd8e8a84942aa8b37c3ea2d5828d8",
      "20e4665f851b485d8d293b11e8891808",
      "ffb01a03c3f94170b08299e0b0f5b04a",
      "9f0b4ddca12d407785f437fce7ba65a6",
      "805cdbedfba7453f92fdd66e498a9f20",
      "b37ea88865f2486d87b7882789e0266b",
      "57f12385772241dd92fa7cab35cbfefd",
      "07da15fafc8b44aa8600f73cdbc8a7fe",
      "2c88ae73e74345528f16de76feb4aa5f",
      "e34ac6c204b54421b8e8c98b3ebf1661",
      "5709d8c0512d4e0e8de0b96b6053e229",
      "69528e5491b04f4a9b831ab54d6df59d",
      "2f17ff666b72456d8182a6534db0bc7e",
      "3a0090562d8b4e6684b064203d8d4c2e",
      "497c5f8b13fa4a32ae714cc76706d2af",
      "42e77166977c4f52b339d32e27240dfe",
      "7265796144bd4a3d89971ef192753251",
      "5846fd552dd44ca1bbb4a2eb7458a5a1",
      "316119b6ddd346ae98cfc8b5fa170fb1",
      "a43805e65b8a4345878c7cbef91eab95",
      "0adf3324b70248fca91fe742d7796fe5",
      "faf6fc065f164d7c9125f9eea73371a7",
      "e9429b62c9fd4079a15b6aaba86c9054",
      "08d205ade3564382990051ffaea740f3",
      "2c1809ff305d4ddeb0b253e3edabee6e",
      "5b866efd5e8148c39a08e166a91b6214"
     ]
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 74510,
     "status": "ok",
     "timestamp": 1755419671995,
     "user": {
      "displayName": "Punit Sobti",
      "userId": "07835938569637239840"
     },
     "user_tz": -330
    },
    "id": "EjNb4WW_gqP0",
    "outputId": "89ae1918-2d63-496b-ae75-d7a5827e1b74"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbb1af5f0f9413c980f43c4c1107126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53520b9d6e7f4d748700fbbb526d4b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203cfc5a56cb4d22b663eb38a7896a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6087ed7953a54aba9e7d0fbe8dd33371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28820bb97b944f2a2d00645ff9ff5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805cdbedfba7453f92fdd66e498a9f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e77166977c4f52b339d32e27240dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 4-bit quantization config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=\"bfloat16\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Prepare model for LoRA\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1755419672033,
     "user": {
      "displayName": "Punit Sobti",
      "userId": "07835938569637239840"
     },
     "user_tz": -330
    },
    "id": "wXrdeOousMFP"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1755419672125,
     "user": {
      "displayName": "Punit Sobti",
      "userId": "07835938569637239840"
     },
     "user_tz": -330
    },
    "id": "6qBQBE_-K0UZ",
    "outputId": "e0a1424d-b7c7-424a-b250-ef4d2f69a2e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 1517111296\n",
      "Trainable parameters: 1843200\n",
      "Non-trainable parameters: 0.1214940528661122\n"
     ]
    }
   ],
   "source": [
    "# Count all parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "\n",
    "# Count only trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n",
    "\n",
    "print(f\"Non-trainable parameters: {trainable_params * 100 / total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 5802,
     "status": "ok",
     "timestamp": 1755419677930,
     "user": {
      "displayName": "Punit Sobti",
      "userId": "07835938569637239840"
     },
     "user_tz": -330
    },
    "id": "YLk58JY2K1U7"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./content/sample_data/logs/peft\",       # Where to save checkpoints\n",
    "    per_device_train_batch_size=4,     # Adjust for GPU memory\\\n",
    "    gradient_accumulation_steps=8,     # Increase effective batch size\n",
    "    learning_rate=2e-4,                # PEFT can use higher LR\n",
    "    weight_decay=0.01,                  # Regularization\n",
    "    num_train_epochs=1,                 # Adjust for dataset size\n",
    "   # max_length=512,                     # Max sequence length\n",
    "    warmup_ratio=0.03,                  # Warmup fraction\n",
    "    lr_scheduler_type=\"cosine\",         # Common choice for LLM tuning\n",
    "    logging_dir=\"./content/sample_data/logs/log\",\n",
    "    logging_steps=10,                   # Log every 10 steps\n",
    "    save_strategy=\"steps\",              # Save model periodically\n",
    "    save_steps=200,\n",
    "   # eval=\"steps\",        # Evaluate periodically\n",
    "    eval_steps=200,\n",
    "    save_total_limit=2,                 # Keep only last 2 checkpoints\n",
    "    #fp16=True,                          # Mixed precision\n",
    "    #bf16=False,                         # If GPU supports bf16, set True\n",
    "    gradient_checkpointing=True,        # Saves memory at cost of compute\n",
    "    optim=\"adamw_torch\",                # AdamW optimizer\n",
    "    report_to=None,            # Or \"wandb\" for Weights & Biases\n",
    "    remove_unused_columns=False,        # Needed for causal LM\n",
    "    push_to_hub=False,\n",
    "    # Upload to HF Hub if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qSMHj6Agtsgk",
    "outputId": "8835f0fe-02e5-4685-cc03-49bdab6c6670"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1292345263.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpunit-sobti\u001b[0m (\u001b[33mpunit-sobti-check\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250817_083611-9l1uamk6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/punit-sobti-check/huggingface/runs/9l1uamk6' target=\"_blank\">fearless-blaze-12</a></strong> to <a href='https://wandb.ai/punit-sobti-check/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/punit-sobti-check/huggingface' target=\"_blank\">https://wandb.ai/punit-sobti-check/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/punit-sobti-check/huggingface/runs/9l1uamk6' target=\"_blank\">https://wandb.ai/punit-sobti-check/huggingface/runs/9l1uamk6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='172' max='308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [172/308 2:30:56 < 2:00:45, 0.02 it/s, Epoch 0.56/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.788000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.632100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.309600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.313100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.299800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.195500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.178600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.138300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.191300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.132600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.127900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.093300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.157600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='225' max='308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [225/308 3:17:58 < 1:13:41, 0.02 it/s, Epoch 0.73/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.788000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.632100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.309600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.313100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.299800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.195500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.178600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.138300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.191300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.132600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.127900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.093300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.157600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.107700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.109400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.163900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.162800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=validate,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9W7AVepk3crc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self, d_model, d_ffn, num_experts, k=1):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.k = k\n",
    "\n",
    "        # Experts: list of independent FFNs\n",
    "        self.experts = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(d_model, d_ffn),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(d_ffn, d_model)\n",
    "            ) for _ in range(num_experts)\n",
    "        ])\n",
    "\n",
    "        # Gating network\n",
    "        self.gate = nn.Linear(d_model, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, seq, d_model]\n",
    "        b, l, d = x.shape\n",
    "\n",
    "        # Gating scores\n",
    "        gate_logits = self.gate(x)  # [b, l, num_experts]\n",
    "        gate_probs = F.softmax(gate_logits, dim=-1)  # per-token distribution\n",
    "\n",
    "        # Pick top-k experts per token\n",
    "        topk_vals, topk_idx = torch.topk(gate_probs, self.k, dim=-1)  # [b, l, k]\n",
    "\n",
    "        print(\"top_vals\",topk_vals.shape)\n",
    "        print(\"top_k\",topk_idx)\n",
    "\n",
    "        # Output buffer\n",
    "        output = torch.zeros_like(x)\n",
    "\n",
    "        for expert_id in range(self.num_experts):\n",
    "            # Mask: which tokens route to this expert\n",
    "            mask = (topk_idx == expert_id)  # [b, l, k]\n",
    "            if not mask.any():\n",
    "                continue\n",
    "            print(\"mask\",mask)\n",
    "            # Get tokens for this expert\n",
    "            mask_any = mask.any(dim=-1)  # [b, l]\n",
    "            print(\"mask_any\",mask_any)\n",
    "            tokens = x[mask_any]  # [num_tokens_for_expert, d_model]\n",
    "            print(\"tokens\",tokens)\n",
    "\n",
    "            # Apply expert\n",
    "            out_tokens = self.experts[expert_id](tokens)\n",
    "            print(\"out_tokens\",out_tokens)\n",
    "\n",
    "            # Scatter back\n",
    "            output[mask_any] = out_tokens\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1754861621848,
     "user": {
      "displayName": "Punit Sobti",
      "userId": "07835938569637239840"
     },
     "user_tz": -60
    },
    "id": "B2gUM_-33fNe",
    "outputId": "a44aecf7-6d10-4997-c16f-757acddfaa79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_vals torch.Size([3, 3, 1])\n",
      "top_k tensor([[[3],\n",
      "         [1],\n",
      "         [2]],\n",
      "\n",
      "        [[3],\n",
      "         [3],\n",
      "         [2]],\n",
      "\n",
      "        [[3],\n",
      "         [2],\n",
      "         [3]]])\n",
      "mask tensor([[[False],\n",
      "         [ True],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False],\n",
      "         [False]]])\n",
      "mask_any tensor([[False,  True, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]])\n",
      "tokens tensor([[0.8047, 0.9771]])\n",
      "out_tokens tensor([[-0.5167, -0.3423]], grad_fn=<AddmmBackward0>)\n",
      "mask tensor([[[False],\n",
      "         [False],\n",
      "         [ True]],\n",
      "\n",
      "        [[False],\n",
      "         [False],\n",
      "         [ True]],\n",
      "\n",
      "        [[False],\n",
      "         [ True],\n",
      "         [False]]])\n",
      "mask_any tensor([[False, False,  True],\n",
      "        [False, False,  True],\n",
      "        [False,  True, False]])\n",
      "tokens tensor([[0.0841, 0.2653],\n",
      "        [0.1111, 0.8782],\n",
      "        [0.0574, 0.7352]])\n",
      "out_tokens tensor([[ 0.1461, -0.0084],\n",
      "        [ 0.1688,  0.0231],\n",
      "        [ 0.1606,  0.0144]], grad_fn=<AddmmBackward0>)\n",
      "mask tensor([[[ True],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[ True],\n",
      "         [ True],\n",
      "         [False]],\n",
      "\n",
      "        [[ True],\n",
      "         [False],\n",
      "         [ True]]])\n",
      "mask_any tensor([[ True, False, False],\n",
      "        [ True,  True, False],\n",
      "        [ True, False,  True]])\n",
      "tokens tensor([[0.8167, 0.0464],\n",
      "        [0.8904, 0.8767],\n",
      "        [0.6312, 0.0613],\n",
      "        [0.4579, 0.5303],\n",
      "        [0.9061, 0.4359]])\n",
      "out_tokens tensor([[ 0.3055, -0.0531],\n",
      "        [ 0.4441,  0.0438],\n",
      "        [ 0.2889, -0.0647],\n",
      "        [ 0.3452, -0.0253],\n",
      "        [ 0.3761, -0.0037]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3055, -0.0531],\n",
       "         [-0.5167, -0.3423],\n",
       "         [ 0.1461, -0.0084]],\n",
       "\n",
       "        [[ 0.4441,  0.0438],\n",
       "         [ 0.2889, -0.0647],\n",
       "         [ 0.1688,  0.0231]],\n",
       "\n",
       "        [[ 0.3452, -0.0253],\n",
       "         [ 0.1606,  0.0144],\n",
       "         [ 0.3761, -0.0037]]], grad_fn=<IndexPutBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MoE(2,4,5)(torch.rand((3, 3, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUZfFDNE4Tlk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN1ie9PEf56VGdzadN9CGC4",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
